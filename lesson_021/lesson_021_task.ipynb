{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7e78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r', errors='ignore', encoding= 'unicode_escape') as f:\n",
    "    data = f.read()\n",
    "    # with split remove whitespaces and multiple spaces\n",
    "    text = ' '.join(data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190b06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the installed model \"en_core_web_sm\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7b5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing text with the nlp object\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fdd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing token attributes\n",
    "output = []\n",
    "for token in doc:\n",
    "    output.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8c4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent attributes as dataframe\n",
    "df = pd.DataFrame(output, columns=['Word', 'Lemma', 'POS', 'TAG', 'DEP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08b5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139402, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fbaf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fifth</td>\n",
       "      <td>Fifth</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elephant</td>\n",
       "      <td>Elephant</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Discworld</td>\n",
       "      <td>Discworld</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Novell</td>\n",
       "      <td>Novell</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Terry</td>\n",
       "      <td>Terry</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pratchett</td>\n",
       "      <td>Pratchett</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They</td>\n",
       "      <td>they</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word      Lemma    POS  TAG       DEP\n",
       "0        The        the    DET   DT       det\n",
       "1      Fifth      Fifth  PROPN  NNP  compound\n",
       "2   Elephant   Elephant  PROPN  NNP  compound\n",
       "3          A          A  PROPN  NNP  compound\n",
       "4  Discworld  Discworld  PROPN  NNP  compound\n",
       "5     Novell     Novell  PROPN  NNP      ROOT\n",
       "6         by         by    ADP   IN      prep\n",
       "7      Terry      Terry  PROPN  NNP  compound\n",
       "8  Pratchett  Pratchett  PROPN  NNP      pobj\n",
       "9       They       they   PRON  PRP     nsubj"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f20c054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates and reindexing\n",
    "df = df.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18679f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20195, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3023f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vocabulary\n",
    "df.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeda51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial lemma list for word2vec\n",
    "lemma_list = [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69337dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train model on lemma list\n",
    "model = gensim.models.Word2Vec(\n",
    "    [lemma_list],\n",
    "    negative = 10, # negative sampling how many \"noise words\" should be drawn\n",
    "    epochs = 100, # iter = 100,\n",
    "    min_count = 1, # ignores all words with total frequency lower than this\n",
    "    window = 7, # maximum distance between the current and predicted word\n",
    "    vector_size = 40 # size = 40 # dimension of the word vector\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3a60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2515882   0.8618007  -0.62189734  0.21660362  1.4357944  -0.9189028\n",
      "  0.5014339   1.9640644   0.9241476   1.7720709   0.9949428  -2.8574426\n",
      " -0.41420013 -1.6200068   0.03121516  0.46067068  1.6498103  -1.5088545\n",
      "  1.2730426   0.12057707  0.9383932  -0.8432872   2.2130914  -0.8925691\n",
      "  1.8986632   1.070426   -0.5505121   0.9107701  -0.46397185  0.18015507\n",
      "  1.8056365   0.54558706  2.3465574   0.41375023  0.09151997  1.8800701\n",
      "  1.071501   -0.5528572  -0.5008159  -0.9496743 ]\n"
     ]
    }
   ],
   "source": [
    "# show result of model work\n",
    "print(model.wv['world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83888ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('build', 0.8675922751426697), ('gravitate', 0.8382787704467773), ('ever', 0.8053116202354431), ('gutte', 0.8022469282150269), ('folkway', 0.798398494720459)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('world', topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f02d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7462981\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('world', 'road'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f305a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('surround', 1.8114854097366333), ('stealthy', 1.7997974157333374), ('bank', 1.7719866037368774), ('gravitate', 1.7695605754852295), ('local', 1.7693874835968018), ('since', 1.73635995388031), ('ever', 1.7125179767608643), ('pass', 1.6898698806762695), ('scan', 1.6774638891220093), ('fortune', 1.6696643829345703)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar_cosmul(positive = ['world','road'], negative = ['sea']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
